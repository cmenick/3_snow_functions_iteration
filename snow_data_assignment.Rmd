---
title: "Snow Data Assignment: Web Scraping, Functions, and Iteration"
author: "Nathan Mueller"
date: "2-7-2022"
output: html_document
---

```{r setup, include=FALSE}
library(rvest)
library(tidyverse)
library(lubridate)
library(readxl)
library(dataRetrieval)
library(dygraphs)
library(xts)
library(magrittr)
```

# Assignment:

1. Extract the meteorological data URLs. Here we want you to use the `rvest` package to get the URLs for the `SASP forcing` and `SBSP_forcing` meteorological datasets.

```{r}
site_url <- 'https://snowstudies.org/archived-data/'

webpage <- read_html(site_url)
webpage

tables <- webpage %>%
  html_nodes('table') %>%
  extract2(3) %>%
  html_table(fill=TRUE)
tables

links <- webpage %>%
  html_nodes('a') %>%
  .[grepl('forcing',.)] %>%
  html_attr('href')

links
```

2. Download the meteorological data. Use the `download_file` and `str_split_fixed` commands to download the data and save it in your data folder. You can use a for loop or a map function. 

```{r}

splits <- str_split_fixed(links,'/',8)
splits

#Keep only the 8th column
dataset <- splits[,8] 
dataset

#generate a file list for where the data goes
file_names <- paste0('data/',dataset)
file_names

for(i in 1:length(file_names)){
  download.file(links[i],destfile=file_names[i])
}

downloaded <- file.exists(file_names)
downloaded

evaluate <- !all(downloaded)
evaluate
```

3. Write a custom function to read in the data and append a site column to the data. 

```{r}
# this code grabs the variable names from the metadata pdf file

library(pdftools)
headers <- pdf_text('https://snowstudies.org/wp-content/uploads/2022/02/Serially-Complete-Metadata-text08.pdf') %>%
  readr::read_lines(.) %>%
  trimws(.) %>%
  str_split_fixed(.,'\\.',2) %>%
  .[,2] %>%
  .[1:26] %>%
  str_trim(side = "left")

# create function that takes the file names and a site column to read in txt file
forcing_reader <- function(file){
  read_table(file,col_names=headers,skip=4) %>%
    select(1:14) %>%
    mutate(site = substr(file,11,11))
}

```

4. Use the `map` function to read in both meteorological files. Display a summary of your tibble.

```{r}

forcing_list <- map(file_names,forcing_reader)
forcing_full <- do.call("rbind", forcing_list)
summary(forcing_full)

```


5. Make a line plot of mean temp by year by site (using the `air temp [K]` variable). Is there anything suspicious in the plot? Adjust your filtering if needed.

```{r}

forcing_summary <- forcing_full %>%
  filter(!is.na(.)) %>%
  group_by(year,site) %>%
  summarize(airtemp = mean(`air temp [K]`))
         
ggplot(forcing_full %>%
         filter(!is.na(.)) %>%
         group_by(year,site) %>%
         summarize(airtemp = mean(`air temp [K]`)), aes(year, airtemp, color=site)) +
  geom_line() +
  scale_x_continuous(breaks=2003:2011)
```

6. Write a function that makes line plots of monthly average temperature at each site for a given year. Use a for loop to make these plots for 2005 to 2010. Are monthly average temperatures at the Senator Beck Study Plot ever warmer than the Snow Angel Study Plot?
Hint: https://ggplot2.tidyverse.org/reference/print.ggplot.html

```{r}
```

Bonus: Make a plot of average daily precipitation by day of year (averaged across all available years). Color each site. 

```{r}
```

Bonus #2: Use a function and for loop to create yearly plots of precipitation by day of year. Color each site. 

```{r}
```
